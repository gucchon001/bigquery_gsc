# 機能要件仕様書

## 1. システム概要
- **プログラムの全体的な目的と対象のユーザー**:
  本プログラムは、Google Search Console（GSC）のデータを取得し、そのデータをGoogle BigQueryに挿入するためのシステムです。主なユーザーは、SEOデータの分析やレポート作成を自動化したいデータアナリストやマーケティング担当者です。

## 2. 主要機能要件
- **データ取得と処理**:
  - `GSCConnector` クラスを利用して、指定された日付範囲のGSCデータを取得します。
  - 取得したデータは、クエリやページURLごとに集計され、クリック数、インプレッション数、平均順位を計算します。

- **データの保存**:
  - 集計されたデータをGoogle BigQueryの指定されたテーブルに挿入します。
  - 挿入時には、日付やURL、クエリ、クリック数、インプレッション数、平均順位などの情報を管理します。

- **進捗管理**:
  - `process_gsc_data` 関数で、GSCデータのフェッチ状況を追跡し、次のフェッチ開始位置を記録します。

- **設定管理**:
  - 環境変数や設定ファイル（`settings.ini`、`secrets.env`）から必要な情報を読み込み、システムの設定を初期化します。

## 3. 非機能要件
- **パフォーマンス**:
  - GSC APIの1日あたりのクォータに従い、効率的にデータをフェッチできるようにバッチサイズを調整しています。
  - BigQueryへのデータ挿入はバッチ処理で行われ、効率的なデータ転送が可能です。

- **セキュリティ**:
  - Googleサービスにアクセスするために、サービスアカウントの認証情報を使用します。これにより、APIキーのセキュリティが確保されています。
  - `.env`ファイルや設定ファイルに機密情報を保持し、`.gitignore`でこれらをバージョン管理から除外しています。

- **可用性**:
  - ロギング機能を備えており、エラーのトラッキングやデバッグが容易です。
  - エラーハンドリングが実装されており、APIエラーやデータ挿入エラーに対して適切な対応を行います。

## 4. 技術要件
- **開発環境**:
  - Python 3.xが必要です。特に依存関係として、Google Cloud関連のライブラリ（`google-cloud-bigquery`、`google-auth`など）とOpenAI API用のライブラリが必要です。
  - `requirements.txt` で指定されているPythonパッケージをインストールする必要があります。

- **システム環境**:
  - 動作にはGoogle Cloud Platform（GCP）のプロジェクト設定と認証情報が必要です。
  - 環境変数や設定ファイルを通じて、APIキーやその他の設定を管理します。

- **必要なライブラリ**:
  - `google-cloud-bigquery`、`google-auth`、`google-api-python-client`、`dotenv`、`pytz`、`icecream`などが必要です。
  - これらのライブラリは、GCPサービスとの連携やロギング、データ処理を容易にします。